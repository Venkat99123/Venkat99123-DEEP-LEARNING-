{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import pipeline ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# sentiment-analysis","metadata":{}},{"cell_type":"code","source":"classifier = pipeline(\"sentiment-analysis\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = classifier(\"Today's weather forecast predicts heavy rain and thunderstorms\")[0]\nprint(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = classifier(\"Dare to be a champion\")[0]\nprint(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# classification model ","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-base\")\n\nclasses = [\"not pharaprase\",\"is pharaprase\"]\n\nsequence_0 = \"The company Amazon is based in Seattle City\"\nsequence_1 = \"Oranges are basically bad for your health\"\nsequence_2 = \"HuggingFace's headquarters are situated in Manhattan\"\n\nparaphrase = tokenizer(sequence_0, sequence_2, return_tensors=\"pt\")\nnot_paraphrase = tokenizer(sequence_0,sequence_2, return_tensors=\"pt\")\n\n\nparaphrase_classification_logits = model(**paraphrase).logits\nnot_paraphrase_classification_logits = model(**not_paraphrase).logits\n\nparaphrase_results = torch.softmax(paraphrase_classification_logits, dim=1).tolist()[0]\nnot_paraphrase_results = torch.softmax(not_paraphrase_classification_logits, dim=1).tolist()[0]\n\nfor i in range(len(classes)):\n    print(f\"{classes[i]}: {int(round(paraphrase_results[i] * 100))}%\")\n\nfor i in range(len(classes)):\n    print(f\"{classes[i]}: {int(round(not_paraphrase_results[i] * 100))}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# question and answering model ","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nquestion_answerer = pipeline(\"question-answering\")\n\ncontext = \"Artificial intelligence (AI) is revolutionizing various industries, including healthcare, finance, and transportation. Its ability to analyze large datasets and perform complex tasks with minimal human intervention has led to significant advancements. Companies are investing heavily in AI research and development to improve efficiency, productivity, and decision-making. However, ethical concerns surrounding AI, such as data privacy and algorithmic bias, remain important considerations in its widespread adoption.\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = question_answerer(question=\"How is artificial intelligence impacting different industries?\", context=context)\nprint(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n\nresult = question_answerer(question=\"What are some examples of tasks that artificial intelligence can perform?\", context=context)\nprint(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# example of question answering using a model and a tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForQuestionAnswering\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\nmodel = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n\ntext = \"The weather department plays a crucial role in forecasting and monitoring meteorological conditions to provide accurate weather predictions. Using advanced technology such as satellites, radar systems, and weather models, meteorologists analyze atmospheric data to forecast temperature, precipitation, wind patterns, and severe weather events. These forecasts are essential for various sectors, including agriculture, aviation, and disaster management, to make informed decisions and mitigate risks associated with adverse weather conditions. Continuous advancements in meteorological science and technology enable the weather department to improve the accuracy and timeliness of weather forecasts, ultimately enhancing public safety and societal resilience to weather-related hazards.\"\n\nquestions = [\n    \"Does the weather department use satellites and radar systems for forecasting?\",\n    \"Are accurate weather forecasts important for sectors like agriculture and aviation?\",\n    \"Do advancements in meteorological science help improve the accuracy of weather predictions?\",\n]\n\nfor question in questions:\n    inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\")\n    input_ids = inputs[\"input_ids\"].tolist()[0]\n    outputs = model(**inputs)\n    answer_start_scores = outputs.start_logits\n    answer_end_scores = outputs.end_logits\n    # Get the most likely beginning of answer with the argmax of the score\n    answer_start = torch.argmax(answer_start_scores)\n    # Get the most likely end of answer with the argmax of the score \n    answer_end = torch.argmax(answer_end_scores) + 1\n    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n    print(f\"Question: {question}\")\n    print(f\"Answer: {answer}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Masked Language Modeling","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unimask = pipeline(\"fill-mask\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pprint(unmasker(f\"HuggingFace's initiative involves building a {unmasker.tokenizer.mask_token} to address NLP challenges, including those related to  weather criteria.\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# example of doing masked language modeling using a model and a tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForMaskedLM, AutoTokenizer\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\nmodel = AutoModelForMaskedLM.from_pretrained(\"distilbert-base-cased\")\n\nsequence = \"Distilled models are smaller than the models they mimic. Using them instead of the large \" \\\n    f\"versions would benefit the entomology department by {tokenizer.mask_token} our understanding of insect behavior.\"\n\ninputs = tokenizer(sequence, return_tensors=\"pt\")\nmask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n\ntoken_logits = model(**inputs).logits\nmask_token_logits = token_logits[0, mask_token_index, :]\n\ntop_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n\nfor token in top_5_tokens:\n    print(sequence.replace(tokenizer.mask_token, tokenizer.decode([token])))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}